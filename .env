AIRFLOW_UID=0
AIRFLOW_GID=0
SPARK_UID=0
SPARK_GID=0

# Home directory setup
AIRFLOW_HOME=/opt/airflow
DBT_HOME=/home/dbt
AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL=10

# Credentials need to match with service postgres-airflow
AIRFLOW_POSTGRES_USER=airflow
AIRFLOW_POSTGRES_PASSWORD=airflow
AIRFLOW_POSTGRES_HOST=postgres-airflow
AIRFLOW_POSTGRES_PORT=5432
AIRFLOW_POSTGRES_DB=airflow

# Credentials need to match with service postgres-dbt
DBT_POSTGRES_PASSWORD=pssd
DBT_POSTGRES_USER =dbtuser
DBT_POSTGRES_DB =dbtdb
DBT_DBT_SCHEMA=dbt
DBT_DBT_RAW_DATA_SCHEMA=dbt_raw_data
DBT_POSTGRES_HOST=postgres-dbt
DBT_POSTGRES_PORT=5432

# Credentials for Airflow SSH Connection
DBT_SSH_HOST=dbt-service
DBT_SSH_PORT=22
SSH_KEY_FILE=/home/airflow/.ssh/id_rsa


# For Spark 
SPARK_APP=/app/spark
SHARED_WORKSPACE=/opt/workspace

SparkVersion=3.2.1
HadoopVersion=3.2
SPARK_HOME: /usr/bin/spark-3.2.1-bin-hadoop3.2
SPARK_MASTER_HOST=spark-master
SPARK_MASTER_PORT=7077
SPARK_MASTER_WEBUI_PORT=8082
SPARK_WORKER_PORT=8081
SPARK_THRIFT_PORT=10000

# Credentials for Jupyter Notebook
JUPYTER_TOKEN=welcome
JUPYTER_USER=jovyan
JUPYTER_UID=0
JUPYTER_GID=0
